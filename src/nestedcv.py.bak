import numpy as np
import pandas as pd
from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold
from sklearn.metrics import (matthews_corrcoef, roc_auc_score, balanced_accuracy_score,
                             f1_score, recall_score, precision_score, confusion_matrix,
                             precision_recall_curve, auc)
import optuna
import warnings

class NestedCV:
    def __init__(self, estimators, paramSpaces, repeats=10, outerLoopsN=5, innerLoopsN=3, seed=42):
        self.estimators = estimators
        self.paramSpaces = paramSpaces
        self.repeats = repeats
        self.outerLoopsN = outerLoopsN
        self.innerLoopsN = innerLoopsN
        self.seed = seed
        self.results = {name: [] for name in estimators}

    def fit(self, X, y):
        rskf = RepeatedStratifiedKFold(splits=self.outerLoopsN, n_repeats=self.repeats, random_state=self.seed)
        for nFold, (trainIndex, testIndex) in enumerate(rskf.split(X, y)):
            trainX, testX = X[trainIndex], X[testIndex]
            trainY, testY = y[trainIndex], y[testIndex]
            for name, estimator in self.estimators.items():
                # Inner CV with Optuna for hyperparameter tuning
                def objective(trial):
                    params = {}
                    for paramName, paramSpace in self.paramSpaces[name].items():
                        if isinstance(paramSpace, list):
                            params[paramName] = trial.suggest_categorical(paramName, paramSpace)
                        elif isinstance(paramSpace, tuple) and len(paramSpace) == 2:
                            params[paramName] = trial.suggest_float(paramName, paramSpace[0], paramSpace[1])
                    clf = estimator.set_params(**params)
                    innerCV = StratifiedKFold(splits=self.innerLoopsN, shuffle=True, random_state=self.seed)
                    scores = []
                    for innerTrainningIndex, innerValidationIndex in innerCV.split(trainX, trainY):
                        innerTrainX, innerValX = trainX[innerTrainningIndex], trainX[innerValidationIndex]
                        innerTrainY, innerValY = trainY[innerTrainningIndex], trainY[innerValidationIndex]
                        with warnings.catch_warnings():
                            warnings.simplefilter("ignore")
                            clf.fit(innerTrainX, innerTrainY)
                        predY = clf.predict(innerValX)
                        mcc = matthews_corrcoef(innerValY, predY)
                        scores.append(mcc)
                    return np.mean(scores)
                study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=self.seed))
                study.optimize(objective, n_trials=30, show_progress_bar=False)
                bestParams = study.bestParams
                bestClf = estimator.set_params(**bestParams)
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    bestClf.fit(trainX, trainY)
                predY = bestClf.predict(testX)
                yProb = bestClf.predict_proba(testX)[:, 1] if hasattr(bestClf, "predict_proba") else bestClf.decision_function(testX)
                # Compute metrics
                mcc = matthews_corrcoef(testY, predY)
                roc_auc = roc_auc_score(testY, yProb)
                ba = balanced_accuracy_score(testY, predY)
                f1 = f1_score(testY, predY)
                recall = recall_score(testY, predY)
                precision = precision_score(testY, predY)
                # F2-score
                f2 = f1_score(testY, predY, beta=2)
                # Specificity
                tn, fp, fn, tp = confusion_matrix(testY, predY).ravel()
                specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
                # PRAUC
                pr, re, _ = precision_recall_curve(testY, yProb)
                prauc = auc(re, pr)
                # NPV
                npv = tn / (tn + fn) if (tn + fn) > 0 else 0
                # Store results
                self.results[name].append({
                    'mcc': mcc,
                    'roc_auc': roc_auc,
                    'balanced_accuracy': ba,
                    'f1': f1,
                    'f2': f2,
                    'recall': recall,
                    'specificity': specificity,
                    'precision': precision,
                    'prauc': prauc,
                    'npv': npv,
                    'bestParams': bestParams
                })

    def getResults(self):
        return self.results
